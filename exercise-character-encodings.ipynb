{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**This notebook is an exercise in the [Data Cleaning](https://www.kaggle.com/learn/data-cleaning) course.  You can reference the tutorial at [this link](https://www.kaggle.com/alexisbcook/character-encodings).**\n\n---\n","metadata":{}},{"cell_type":"markdown","source":"In this exercise, you'll apply what you learned in the **Character encodings** tutorial.\n\n# Setup\n\nThe questions below will give you feedback on your work. Run the following cell to set up the feedback system.","metadata":{}},{"cell_type":"code","source":"from learntools.core import binder\nbinder.bind(globals())\nfrom learntools.data_cleaning.ex4 import *\nprint(\"Setup Complete\")","metadata":{"execution":{"iopub.status.busy":"2023-07-11T14:24:00.830678Z","iopub.execute_input":"2023-07-11T14:24:00.831068Z","iopub.status.idle":"2023-07-11T14:24:00.947215Z","shell.execute_reply.started":"2023-07-11T14:24:00.831032Z","shell.execute_reply":"2023-07-11T14:24:00.946021Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Setup Complete\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Get our environment set up\n\nThe first thing we'll need to do is load in the libraries we'll be using.","metadata":{}},{"cell_type":"code","source":"# modules we'll use\nimport pandas as pd\nimport numpy as np\n\n# helpful character encoding module\nimport charset_normalizer\n\n# set seed for reproducibility\nnp.random.seed(0)","metadata":{"execution":{"iopub.status.busy":"2023-07-11T14:24:54.976176Z","iopub.execute_input":"2023-07-11T14:24:54.976607Z","iopub.status.idle":"2023-07-11T14:24:54.982323Z","shell.execute_reply.started":"2023-07-11T14:24:54.976554Z","shell.execute_reply":"2023-07-11T14:24:54.981221Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# 1) What are encodings?\n\nYou're working with a dataset composed of bytes.  Run the code cell below to print a sample entry.","metadata":{}},{"cell_type":"code","source":"sample_entry = b'\\xa7A\\xa6n'\nprint(sample_entry)\nprint('data type:', type(sample_entry))","metadata":{"execution":{"iopub.status.busy":"2023-07-11T14:24:58.142522Z","iopub.execute_input":"2023-07-11T14:24:58.143357Z","iopub.status.idle":"2023-07-11T14:24:58.149785Z","shell.execute_reply.started":"2023-07-11T14:24:58.143311Z","shell.execute_reply":"2023-07-11T14:24:58.148679Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"b'\\xa7A\\xa6n'\ndata type: <class 'bytes'>\n","output_type":"stream"}]},{"cell_type":"markdown","source":"You notice that it doesn't use the standard UTF-8 encoding. \n\nUse the next code cell to create a variable `new_entry` that changes the encoding from `\"big5-tw\"` to `\"utf-8\"`.  `new_entry` should have the bytes datatype.","metadata":{}},{"cell_type":"code","source":"before = sample_entry.decode(\"big5-tw\")\nnew_entry = before.encode()\n\n# Check your answer\nq1.check()","metadata":{"execution":{"iopub.status.busy":"2023-07-11T14:32:15.150207Z","iopub.execute_input":"2023-07-11T14:32:15.150642Z","iopub.status.idle":"2023-07-11T14:32:15.160640Z","shell.execute_reply.started":"2023-07-11T14:32:15.150573Z","shell.execute_reply":"2023-07-11T14:32:15.159481Z"},"trusted":true},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"outcomeType\": 1, \"valueTowardsCompletion\": 0.3333333333333333, \"interactionType\": 1, \"questionType\": 1, \"questionId\": \"1_EncodingsIntro\", \"learnToolsVersion\": \"0.3.4\", \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\"}}, \"*\")"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Correct","text/markdown":"<span style=\"color:#33cc33\">Correct</span>"},"metadata":{}}]},{"cell_type":"code","source":"# Lines below will give you a hint or solution code\n#q1.hint()\n#q1.solution()","metadata":{"execution":{"iopub.status.busy":"2023-07-11T14:32:20.169225Z","iopub.execute_input":"2023-07-11T14:32:20.169686Z","iopub.status.idle":"2023-07-11T14:32:20.174251Z","shell.execute_reply.started":"2023-07-11T14:32:20.169647Z","shell.execute_reply":"2023-07-11T14:32:20.172813Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"# 2) Reading in files with encoding problems\n\nUse the code cell below to read in this file at path `\"../input/fatal-police-shootings-in-the-us/PoliceKillingsUS.csv\"`.  \n\nFigure out what the correct encoding should be and read in the file to a DataFrame `police_killings`.","metadata":{}},{"cell_type":"code","source":"# TODO: Load in the DataFrame correctly.\npolice_killings = pd.read_csv(\"../input/fatal-police-shootings-in-the-us/PoliceKillingsUS.csv\", encoding='Windows-1252')\n\n# Check your answer\nq2.check()","metadata":{"execution":{"iopub.status.busy":"2023-07-11T14:49:44.594772Z","iopub.execute_input":"2023-07-11T14:49:44.595162Z","iopub.status.idle":"2023-07-11T14:49:44.625879Z","shell.execute_reply.started":"2023-07-11T14:49:44.595127Z","shell.execute_reply":"2023-07-11T14:49:44.624744Z"},"trusted":true},"execution_count":23,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"outcomeType\": 1, \"valueTowardsCompletion\": 0.3333333333333333, \"interactionType\": 1, \"questionType\": 1, \"questionId\": \"2_ReadIn\", \"learnToolsVersion\": \"0.3.4\", \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\"}}, \"*\")"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Correct","text/markdown":"<span style=\"color:#33cc33\">Correct</span>"},"metadata":{}}]},{"cell_type":"markdown","source":"Feel free to use any additional code cells for supplemental work.  To get credit for finishing this question, you'll need to run `q2.check()` and get a result of **Correct**.","metadata":{}},{"cell_type":"code","source":"with open(\"../input/fatal-police-shootings-in-the-us/PoliceKillingsUS.csv\") as rawdata:\n    result = charset_normalizer.detect(rawdata.read(10000))\nprint(result)","metadata":{"execution":{"iopub.status.busy":"2023-07-11T14:48:04.272727Z","iopub.execute_input":"2023-07-11T14:48:04.273107Z","iopub.status.idle":"2023-07-11T14:48:04.322654Z","shell.execute_reply.started":"2023-07-11T14:48:04.273071Z","shell.execute_reply":"2023-07-11T14:48:04.321019Z"},"trusted":true},"execution_count":21,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[21], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../input/fatal-police-shootings-in-the-us/PoliceKillingsUS.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m rawdata:\n\u001b[0;32m----> 2\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mcharset_normalizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrawdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(result)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/charset_normalizer/legacy.py:28\u001b[0m, in \u001b[0;36mdetect\u001b[0;34m(byte_str, should_rename_legacy, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m     warn(\n\u001b[1;32m     24\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcharset-normalizer disregard arguments \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mlist\u001b[39m(kwargs\u001b[38;5;241m.\u001b[39mkeys()))\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m in legacy function detect()\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     25\u001b[0m     )\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(byte_str, (\u001b[38;5;28mbytearray\u001b[39m, \u001b[38;5;28mbytes\u001b[39m)):\n\u001b[0;32m---> 28\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(  \u001b[38;5;66;03m# pragma: nocover\u001b[39;00m\n\u001b[1;32m     29\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected object of type bytes or bytearray, got: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     30\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mtype\u001b[39m(byte_str))\n\u001b[1;32m     31\u001b[0m     )\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(byte_str, \u001b[38;5;28mbytearray\u001b[39m):\n\u001b[1;32m     34\u001b[0m     byte_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbytes\u001b[39m(byte_str)\n","\u001b[0;31mTypeError\u001b[0m: Expected object of type bytes or bytearray, got: <class 'str'>"],"ename":"TypeError","evalue":"Expected object of type bytes or bytearray, got: <class 'str'>","output_type":"error"}]},{"cell_type":"code","source":"# Lines below will give you a hint or solution code\n#q2.hint()\n#q2.solution()","metadata":{"execution":{"iopub.status.busy":"2023-07-11T14:49:53.890058Z","iopub.execute_input":"2023-07-11T14:49:53.890463Z","iopub.status.idle":"2023-07-11T14:49:53.895569Z","shell.execute_reply.started":"2023-07-11T14:49:53.890428Z","shell.execute_reply":"2023-07-11T14:49:53.894197Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"# 3) Saving your files with UTF-8 encoding\n\nSave a version of the police killings dataset to CSV with UTF-8 encoding.  Your answer will be marked correct after saving this file.  \n\nNote: When using the `to_csv()` method, supply only the name of the file (e.g., `\"my_file.csv\"`).  This saves the file at the filepath `\"/kaggle/working/my_file.csv\"`.","metadata":{}},{"cell_type":"code","source":"# TODO: Save the police killings dataset to CSV\ncsv = police_killings.to_csv(\"my_file.csv\")\n\n# Check your answer\nq3.check()","metadata":{"execution":{"iopub.status.busy":"2023-07-11T14:52:06.876818Z","iopub.execute_input":"2023-07-11T14:52:06.877223Z","iopub.status.idle":"2023-07-11T14:52:06.919137Z","shell.execute_reply.started":"2023-07-11T14:52:06.877189Z","shell.execute_reply":"2023-07-11T14:52:06.918195Z"},"trusted":true},"execution_count":31,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"outcomeType\": 1, \"valueTowardsCompletion\": 0.3333333333333333, \"interactionType\": 1, \"questionType\": 2, \"questionId\": \"3_SaveCSV\", \"learnToolsVersion\": \"0.3.4\", \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\"}}, \"*\")"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Correct","text/markdown":"<span style=\"color:#33cc33\">Correct</span>"},"metadata":{}}]},{"cell_type":"code","source":"# Lines below will give you a hint or solution code\n#q3.hint()\nq3.solution()","metadata":{"execution":{"iopub.status.busy":"2023-07-11T14:51:45.151254Z","iopub.execute_input":"2023-07-11T14:51:45.151680Z","iopub.status.idle":"2023-07-11T14:51:45.160291Z","shell.execute_reply.started":"2023-07-11T14:51:45.151645Z","shell.execute_reply":"2023-07-11T14:51:45.159172Z"},"trusted":true},"execution_count":30,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"interactionType\": 3, \"questionType\": 2, \"questionId\": \"3_SaveCSV\", \"learnToolsVersion\": \"0.3.4\", \"valueTowardsCompletion\": 0.0, \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\", \"outcomeType\": 4}}, \"*\")"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Solution: \n```python\n\npolice_killings.to_csv(\"my_file.csv\")\n\n```","text/markdown":"<span style=\"color:#33cc99\">Solution:</span> \n```python\n\npolice_killings.to_csv(\"my_file.csv\")\n\n```"},"metadata":{}}]},{"cell_type":"markdown","source":"# (Optional) More practice\n\nCheck out [this dataset of files in different character encodings](https://www.kaggle.com/rtatman/character-encoding-examples). Can you read in all the files with their original encodings and them save them out as UTF-8 files?\n\nIf you have a file that's in UTF-8 but has just a couple of weird-looking characters in it, you can try out the [ftfy module](https://ftfy.readthedocs.io/en/latest/#) and see if it helps. \n\n# Keep going\n\nIn the final lesson, learn how to [**clean up inconsistent text entries**](https://www.kaggle.com/alexisbcook/inconsistent-data-entry) in your dataset.","metadata":{}},{"cell_type":"markdown","source":"---\n\n\n\n\n*Have questions or comments? Visit the [course discussion forum](https://www.kaggle.com/learn/data-cleaning/discussion) to chat with other learners.*","metadata":{}}]}